#!/usr/bin/env python3
"""
æœ€ç»ˆæµ‹è¯• GLM æ¨¡å‹é…ç½®ä¿®å¤
"""

import os
import sys
sys.path.append('/Users/danceiny/hotelcode/pr-agent-1')

try:
    import litellm
    
    # æ¨¡æ‹Ÿ GitHub Action ä¸­çš„ç¯å¢ƒå˜é‡è®¾ç½®
    os.environ["OPENAI_API_KEY"] = "9fcd4114657045f693f3e1d0b88fa3da.7A85nV6VHjnv3r85"
    os.environ["OPENAI_API_BASE"] = "https://open.bigmodel.cn/api/paas/v4"
    
    print("=== GLM æ¨¡å‹é…ç½®ä¿®å¤æµ‹è¯• ===")
    print(f"litellm version: {litellm.__version__ if hasattr(litellm, '__version__') else 'unknown'}")
    
    # æµ‹è¯•ä¿®å¤åçš„æ¨¡å‹åç§°æ ¼å¼
    correct_model = "openai/glm-4.6"
    incorrect_models = ["glm-4.6", "zhipu/glm-4.6"]
    
    messages = [{"role": "user", "content": "Hello, this is a test message."}]
    
    print(f"\n1. æµ‹è¯•æ­£ç¡®çš„æ¨¡å‹æ ¼å¼: {correct_model}")
    try:
        # ä½¿ç”¨ mock å“åº”æµ‹è¯•
        response = litellm.completion(
            model=correct_model,
            messages=messages,
            mock_response="Test response from GLM-4.6",
            api_base=os.environ.get("OPENAI_API_BASE"),
            api_key=os.environ.get("OPENAI_API_KEY")
        )
        print(f"  âœ… æˆåŠŸ: {correct_model} å¯ä»¥æ­£å¸¸å·¥ä½œ")
        print(f"  å“åº”: {response.choices[0].message.content}")
    except Exception as e:
        print(f"  âŒ å¤±è´¥: {e}")
    
    print(f"\n2. éªŒè¯é”™è¯¯çš„æ¨¡å‹æ ¼å¼ä¼šå¤±è´¥:")
    for model in incorrect_models:
        try:
            response = litellm.completion(
                model=model,
                messages=messages,
                mock_response="This should fail",
                api_base=os.environ.get("OPENAI_API_BASE"),
                api_key=os.environ.get("OPENAI_API_KEY")
            )
            print(f"  âš ï¸  æ„å¤–æˆåŠŸ: {model}")
        except Exception as e:
            if "LLM Provider NOT provided" in str(e):
                print(f"  âœ… é¢„æœŸå¤±è´¥: {model} - Provider æœªè¯†åˆ«")
            else:
                print(f"  âŒ å…¶ä»–é”™è¯¯: {model} - {e}")
    
    # æ£€æŸ¥ pr-agent çš„ MAX_TOKENS é…ç½®
    print(f"\n3. æ£€æŸ¥ pr-agent MAX_TOKENS é…ç½®:")
    try:
        from pr_agent.algo import MAX_TOKENS
        
        models_to_check = ["glm-4.6", "zhipu/glm-4.6", "openai/glm-4.6"]
        for model in models_to_check:
            if model in MAX_TOKENS:
                print(f"  âœ… {model}: {MAX_TOKENS[model]} tokens")
            else:
                print(f"  âŒ {model}: æœªåœ¨ MAX_TOKENS ä¸­æ‰¾åˆ°")
                
        # å»ºè®®æ·»åŠ  openai/glm-4.6 åˆ° MAX_TOKENS
        if "openai/glm-4.6" not in MAX_TOKENS:
            print(f"\n  ğŸ’¡ å»ºè®®: éœ€è¦åœ¨ MAX_TOKENS ä¸­æ·»åŠ  'openai/glm-4.6': 200000")
        
    except ImportError as e:
        print(f"  âŒ æ— æ³•å¯¼å…¥ pr-agent MAX_TOKENS: {e}")
    
    print(f"\n=== ä¿®å¤å»ºè®® ===")
    print(f"1. åœ¨ GitHub Action é…ç½®ä¸­ä½¿ç”¨: config.model: \"openai/glm-4.6\"")
    print(f"2. ç¡®ä¿ OPENAI_API_KEY å’Œ OPENAI_API_BASE æ­£ç¡®è®¾ç½®")
    print(f"3. å¦‚æœéœ€è¦ï¼Œåœ¨ pr_agent/algo/__init__.py çš„ MAX_TOKENS ä¸­æ·»åŠ :")
    print(f"   \"openai/glm-4.6\": 200000")

except ImportError as e:
    print(f"Could not import litellm: {e}")
except Exception as e:
    print(f"Error: {e}")